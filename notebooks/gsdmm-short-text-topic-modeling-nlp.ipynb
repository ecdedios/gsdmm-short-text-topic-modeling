{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behavioral-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(493)\n",
    "\n",
    "# to print out all the outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-hypothetical",
   "metadata": {},
   "source": [
    "# GET THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satisfactory-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "smoking-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/in/trump-archive.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "front-rebel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-16 19:01:06</td>\n",
       "      <td>163597</td>\n",
       "      <td>1339284435456421888</td>\n",
       "      <td>False</td>\n",
       "      <td>42842</td>\n",
       "      <td>https://t.co/GgwnkrGz9U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-16 18:51:14</td>\n",
       "      <td>222413</td>\n",
       "      <td>1339281950490697728</td>\n",
       "      <td>False</td>\n",
       "      <td>52018</td>\n",
       "      <td>Chris Krebs was totally excoriated and proven wrong at the Senate Hearing on the Fraudulent 2020 Election. Massive FRAUD took place with machines, people voting from out of state, illegals, dead people, no signatures—and so much more!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-16 18:33:10</td>\n",
       "      <td>246740</td>\n",
       "      <td>1339277405458997248</td>\n",
       "      <td>False</td>\n",
       "      <td>51116</td>\n",
       "      <td>Former United States Solicitor General Ken Starr: Pennsylvania “Flagrantly Violated” Laws Ahead of Election.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-16 18:27:02</td>\n",
       "      <td>179518</td>\n",
       "      <td>1339275859841134592</td>\n",
       "      <td>False</td>\n",
       "      <td>38198</td>\n",
       "      <td>Senate Hearings going on LIVE @OANN, as to the Fraudulent 2020 Election that just took place. @SenRonJohnson doing an excellent job. Nevada must be flipped based on testimony!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-16 15:06:47</td>\n",
       "      <td>258927</td>\n",
       "      <td>1339225465584840704</td>\n",
       "      <td>False</td>\n",
       "      <td>53928</td>\n",
       "      <td>Perhaps the biggest difference between 2016 and 2020 is @FoxNews, despite the fact that I went from 63,000,000 Votes to 75,000,000 Votes, a record 12,000,000 Vote increase. Obama went down 3,000,000 Votes, and won. Rigged Election!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  favorites                   id  isRetweet  retweets  \\\n",
       "0 2020-12-16 19:01:06     163597  1339284435456421888      False     42842   \n",
       "1 2020-12-16 18:51:14     222413  1339281950490697728      False     52018   \n",
       "2 2020-12-16 18:33:10     246740  1339277405458997248      False     51116   \n",
       "3 2020-12-16 18:27:02     179518  1339275859841134592      False     38198   \n",
       "4 2020-12-16 15:06:47     258927  1339225465584840704      False     53928   \n",
       "\n",
       "                                                                                                                                                                                                                                         text  \n",
       "0                                                                                                                                                                                                                     https://t.co/GgwnkrGz9U  \n",
       "1  Chris Krebs was totally excoriated and proven wrong at the Senate Hearing on the Fraudulent 2020 Election. Massive FRAUD took place with machines, people voting from out of state, illegals, dead people, no signatures—and so much more!  \n",
       "2                                                                                                                                Former United States Solicitor General Ken Starr: Pennsylvania “Flagrantly Violated” Laws Ahead of Election.  \n",
       "3                                                             Senate Hearings going on LIVE @OANN, as to the Fraudulent 2020 Election that just took place. @SenRonJohnson doing an excellent job. Nevada must be flipped based on testimony!  \n",
       "4   Perhaps the biggest difference between 2016 and 2020 is @FoxNews, despite the fact that I went from 63,000,000 Votes to 75,000,000 Votes, a record 12,000,000 Vote increase. Obama went down 3,000,000 Votes, and won. Rigged Election!!!  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-copyright",
   "metadata": {},
   "source": [
    "# PRE-PROCESS TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "injured-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interstate-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove  null values\n",
    "df = df.loc[df.text.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "selected-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(original):\n",
    "    word = original.lower()\n",
    "    word = unicodedata.normalize('NFKD', word)\\\n",
    "                                .encode('ascii', 'ignore')\\\n",
    "                                .decode('utf-8', 'ignore')\n",
    "    word = re.sub(r\"[^a-z0-9'\\s]\", '', word)\n",
    "    word = word.replace('\\n',' ')\n",
    "    word = word.replace('\\t',' ')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "excited-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(original, extra_words=[], exclude_words=[]):\n",
    "    stopword_list = stopwords.words('english')\n",
    "\n",
    "    for word in extra_words:\n",
    "        stopword_list.append(word)\n",
    "    for word in exclude_words:\n",
    "        stopword_list.remove(word)\n",
    "\n",
    "    words = original.split()\n",
    "    filtered_words = [w for w in words if w not in stopword_list]\n",
    "\n",
    "    original_nostop = ' '.join(filtered_words)\n",
    "\n",
    "    return original_nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "revolutionary-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(original):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in original.split()]\n",
    "    original_stemmed = ' '.join(stems)\n",
    "    return original_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conditional-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for sentence in df.text:\n",
    "    words = word_tokenize(stem(remove_stopwords(basic_clean(sentence))))\n",
    "    docs.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-danger",
   "metadata": {},
   "source": [
    "# GSDMM MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "supported-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsdmm import MovieGroupProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "classical-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 784 clusters with 15 clusters populated\n",
      "In stage 1: transferred 576 clusters with 15 clusters populated\n",
      "In stage 2: transferred 400 clusters with 15 clusters populated\n",
      "In stage 3: transferred 332 clusters with 14 clusters populated\n",
      "In stage 4: transferred 299 clusters with 13 clusters populated\n",
      "In stage 5: transferred 237 clusters with 10 clusters populated\n",
      "In stage 6: transferred 247 clusters with 10 clusters populated\n",
      "In stage 7: transferred 235 clusters with 11 clusters populated\n",
      "In stage 8: transferred 218 clusters with 10 clusters populated\n",
      "In stage 9: transferred 256 clusters with 9 clusters populated\n",
      "In stage 10: transferred 240 clusters with 9 clusters populated\n",
      "In stage 11: transferred 227 clusters with 9 clusters populated\n",
      "In stage 12: transferred 220 clusters with 9 clusters populated\n",
      "In stage 13: transferred 220 clusters with 9 clusters populated\n",
      "In stage 14: transferred 239 clusters with 10 clusters populated\n",
      "In stage 15: transferred 230 clusters with 10 clusters populated\n",
      "In stage 16: transferred 236 clusters with 9 clusters populated\n",
      "In stage 17: transferred 218 clusters with 9 clusters populated\n",
      "In stage 18: transferred 240 clusters with 10 clusters populated\n",
      "In stage 19: transferred 229 clusters with 10 clusters populated\n",
      "In stage 20: transferred 224 clusters with 9 clusters populated\n",
      "In stage 21: transferred 226 clusters with 10 clusters populated\n",
      "In stage 22: transferred 226 clusters with 9 clusters populated\n",
      "In stage 23: transferred 225 clusters with 9 clusters populated\n",
      "In stage 24: transferred 226 clusters with 11 clusters populated\n",
      "In stage 25: transferred 222 clusters with 11 clusters populated\n",
      "In stage 26: transferred 252 clusters with 10 clusters populated\n",
      "In stage 27: transferred 238 clusters with 9 clusters populated\n",
      "In stage 28: transferred 207 clusters with 9 clusters populated\n",
      "In stage 29: transferred 212 clusters with 10 clusters populated\n"
     ]
    }
   ],
   "source": [
    "mgp = MovieGroupProcess(K=15, alpha=0.1, beta=1, n_iters=30)\n",
    "\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)\n",
    "\n",
    "y = mgp.fit(docs, n_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fitting-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save model\n",
    "# with open('../data/out/v493_trump_archive_k5.model', 'wb') as f:\n",
    "#     pickle.dump(mgp, f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "finite-sudan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [173   0   1   7   0  37   0   0   4  14   2 539 151   0   4]\n"
     ]
    }
   ],
   "source": [
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "composite-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important clusters (by number of docs inside): [11  0 12  5  9  3 14  8 10  2 13  7  6  4  1]\n"
     ]
    }
   ],
   "source": [
    "top_index = doc_count.argsort()[-15:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "important-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print('Cluster %s : %s'%(cluster,sort_dicts))\n",
    "        print('-'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "improving-morocco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 11 : [('elect', 212), ('vote', 184), ('state', 108), ('peopl', 66), ('fraud', 61)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 0 : [('great', 26), ('thank', 20), ('vaccin', 16), ('peopl', 15), ('news', 13)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 12 : [('georgia', 65), ('signatur', 45), ('briankempga', 41), ('state', 40), ('governor', 37)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 5 : [('nation', 20), ('defens', 12), ('section', 12), ('230', 12), ('amp', 11)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 9 : [('peopl', 8), ('attack', 6), ('back', 5), ('antifa', 5), ('dc', 4)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 3 : [('recogn', 6), ('bill', 4), ('sovereignti', 4), ('western', 4), ('sahara', 4)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 14 : [('republican', 2), ('senat', 2), ('import', 2), ('action', 2), ('need', 2)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 8 : [('breakthrough', 4), ('massiv', 2), ('two', 2), ('great', 2), ('anoth', 2)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 10 : [('attorney', 6), ('gener', 6), ('deputi', 4), ('act', 2), ('jeff', 2)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 2 : [('httpstcozph2ddb38k', 1)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 13 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 7 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 6 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 4 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 1 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show the top 5 words in term frequency for each cluster \n",
    "top_words(mgp.cluster_word_distribution, top_index, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quality-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {}\n",
    "topic_names = ['Topic #1',\n",
    "               'Topic #2',\n",
    "               'Topic #3',\n",
    "               'Topic #4',\n",
    "               'Topic #5',\n",
    "               'Topic #6',\n",
    "               'Topic #7',\n",
    "               'Topic #8',\n",
    "               'Topic #9',\n",
    "               'Topic #10',\n",
    "               'Topic #11',\n",
    "               'Topic #12',\n",
    "               'Topic #13',\n",
    "               'Topic #14',\n",
    "               'Topic #15'\n",
    "              ]\n",
    "for i, topic_num in enumerate(top_index):\n",
    "    topic_dict[topic_num]=topic_names[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "altered-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topics_dataframe(data_text=df.text,  mgp=mgp, threshold=0.3, topic_dict=topic_dict, stem_text=docs):\n",
    "    result = pd.DataFrame(columns=['text', 'topic', 'stems'])\n",
    "    for i, text in enumerate(data_text):\n",
    "        result.at[i, 'text'] = text\n",
    "        result.at[i, 'stems'] = stem_text[i]\n",
    "        prob = mgp.choose_best_label(stem_text[i])\n",
    "        if prob[1] >= threshold:\n",
    "            result.at[i, 'topic'] = topic_dict[prob[0]]\n",
    "        else:\n",
    "            result.at[i, 'topic'] = 'Other'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "steady-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = create_topics_dataframe(data_text=df.text,  mgp=mgp, threshold=0.3, topic_dict=topic_dict, stem_text=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sound-egyptian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/GgwnkrGz9U</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>[httpstcoggwnkrgz9u]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chris Krebs was totally excoriated and proven wrong at the Senate Hearing on the Fraudulent 2020 Election. Massive FRAUD took place with machines, people voting from out of state, illegals, dead people, no signatures—and so much more!</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>[chri, kreb, total, excori, proven, wrong, senat, hear, fraudul, 2020, elect, massiv, fraud, took, place, machin, peopl, vote, state, illeg, dead, peopl, signaturesand, much]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Former United States Solicitor General Ken Starr: Pennsylvania “Flagrantly Violated” Laws Ahead of Election.</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>[former, unit, state, solicitor, gener, ken, starr, pennsylvania, flagrantli, violat, law, ahead, elect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senate Hearings going on LIVE @OANN, as to the Fraudulent 2020 Election that just took place. @SenRonJohnson doing an excellent job. Nevada must be flipped based on testimony!</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>[senat, hear, go, live, oann, fraudul, 2020, elect, took, place, senronjohnson, excel, job, nevada, must, flip, base, testimoni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perhaps the biggest difference between 2016 and 2020 is @FoxNews, despite the fact that I went from 63,000,000 Votes to 75,000,000 Votes, a record 12,000,000 Vote increase. Obama went down 3,000,000 Votes, and won. Rigged Election!!!</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>[perhap, biggest, differ, 2016, 2020, foxnew, despit, fact, went, 63000000, vote, 75000000, vote, record, 12000000, vote, increas, obama, went, 3000000, vote, rig, elect]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                         text  \\\n",
       "0                                                                                                                                                                                                                     https://t.co/GgwnkrGz9U   \n",
       "1  Chris Krebs was totally excoriated and proven wrong at the Senate Hearing on the Fraudulent 2020 Election. Massive FRAUD took place with machines, people voting from out of state, illegals, dead people, no signatures—and so much more!   \n",
       "2                                                                                                                                Former United States Solicitor General Ken Starr: Pennsylvania “Flagrantly Violated” Laws Ahead of Election.   \n",
       "3                                                             Senate Hearings going on LIVE @OANN, as to the Fraudulent 2020 Election that just took place. @SenRonJohnson doing an excellent job. Nevada must be flipped based on testimony!   \n",
       "4   Perhaps the biggest difference between 2016 and 2020 is @FoxNews, despite the fact that I went from 63,000,000 Votes to 75,000,000 Votes, a record 12,000,000 Vote increase. Obama went down 3,000,000 Votes, and won. Rigged Election!!!   \n",
       "\n",
       "      topic  \\\n",
       "0  Topic #1   \n",
       "1  Topic #1   \n",
       "2  Topic #1   \n",
       "3  Topic #1   \n",
       "4  Topic #1   \n",
       "\n",
       "                                                                                                                                                                            stems  \n",
       "0                                                                                                                                                            [httpstcoggwnkrgz9u]  \n",
       "1  [chri, kreb, total, excori, proven, wrong, senat, hear, fraudul, 2020, elect, massiv, fraud, took, place, machin, peopl, vote, state, illeg, dead, peopl, signaturesand, much]  \n",
       "2                                                                        [former, unit, state, solicitor, gener, ken, starr, pennsylvania, flagrantli, violat, law, ahead, elect]  \n",
       "3                                                [senat, hear, go, live, oann, fraudul, 2020, elect, took, place, senronjohnson, excel, job, nevada, must, flip, base, testimoni]  \n",
       "4      [perhap, biggest, differ, 2016, 2020, foxnew, despit, fact, went, 63000000, vote, 75000000, vote, record, 12000000, vote, increas, obama, went, 3000000, vote, rig, elect]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abandoned-flexibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic #1    575\n",
       "Topic #2    180\n",
       "Topic #3    137\n",
       "Topic #4     18\n",
       "Topic #5      8\n",
       "Topic #6      6\n",
       "Topic #7      3\n",
       "Topic #8      2\n",
       "Topic #9      2\n",
       "Other         1\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.topic.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-liquid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
